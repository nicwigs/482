{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSE 482: Big Data Analysis (Spring 2019) Homework 2 Solution\n",
    "\n",
    "Due date: February 20, 2019 (before midnight)\n",
    "\n",
    "Submit your homework using the D2L system. Use the notebook below to write the solution of your homework. Make sure you submit the notebook along with its HTML version."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1.** Consider the dataset shown in the table below.\n",
    "\n",
    "<img src = \"figure1.jpg\" width=\"350\">\n",
    "\n",
    "Note that x1 through x9 are integer-valued counts sorted in ascending order (i.e., x1 corresponds to the lowest cell count while x9 has the highest cell count). Suppose we apply the following methods (equal interval width, equal frequency, and entropy-based) to discretize the blood cell count attribute into 3 bins. The bins obtained are listed below:\n",
    "\n",
    "    - Equal Width: \n",
    "        - Bin 1: x1, x2  \n",
    "        - Bin 2: x3, x4, x5, x6, x7, x8\n",
    "        - Bin 3: x9\n",
    "\n",
    "    - Equal Frequency: \n",
    "        - Bin 1: x1, x2, x3 \n",
    "        - Bin 2: x4, x5, x6 \n",
    "        - Bin 3: x7, x8, x9\n",
    "    \n",
    "    - Entropy-based discretization with smoking status as class attribute: \n",
    "        - Bin 1: x1, x2\n",
    "        - Bin 2: x3, x4, x5\n",
    "        - Bin 3: x6, x7, x8, x9\n",
    "\n",
    "Explain the effect of applying each transformation below on the discretization methods listed above. Specifically, state whether the elements assigned to the bins can change to a different bin if you apply discretization on the transformed attribute values. \n",
    "\n",
    "(a) Centering the attribute: $x \\rightarrow x - m$\n",
    "\n",
    "(b) Standardizing the attribute: $x \\rightarrow \\frac{x - m}{s}$\n",
    "\n",
    "(c) Applying logarithmic transform: $x \\rightarrow \\log(x)$\n",
    "\n",
    "where x corresponds to one of the original blood count values (x1 to x9), m denotes the mean (average) value of the 9 numbers, and s denotes the standard deviation of the 9 numbers. Note: you do not need to know the exact values of x1 to x9 in order to answer this question. \n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " (a) Centering the attribute\n",
    " \n",
    "     i. Equal-width: No change because the distance between every pair of adjacent points remains unchanged. \n",
    "     \n",
    "     ii. Equal frequency: No change because the transformation does not alter the relative ordering of the points.\n",
    "     \n",
    "     iii. Entropy-based: No change because the transformation does not alter the relative ordering of the points.\n",
    " \n",
    " (b) Standardizing the attribute\n",
    " \n",
    "     i. Equal-width: No change. After the transformation, the distance between every pair of adjacent points reduces uniformly by a constant factor of s. However, the bin size also reduces by the same constant factor s. Thus, the membership in each of the 3 bins remains the same. \n",
    "     \n",
    "     ii. Equal frequency: No change because the transformation does not alter the relative ordering of the points. \n",
    "     \n",
    "     iii. Entropy-based: No change because the transformation does not alter the relative ordering of the points.\n",
    "\n",
    " (c) Applying log transform:\n",
    " \n",
    "     i. Equal-width: The transformation will change the relative distance between pairs of adjacent points. As a result, the bin elements may also change.\n",
    "     \n",
    "     ii. Equal frequency: No change because the transformation does not alter the relative ordering of the points.\n",
    "     \n",
    "     iii. Entropy-based: No change because the transformation does not alter the relative ordering of the points.\n",
    " \n",
    "Note: You do not have to list the elements assigned to each bin after the  transformation and discretization. You only need to answer whether it is possible for some of the elements to change their bin membership after the transformation and discretization. For example, suppose x3 was originally assigned to bin #2 using the equal width method. After applying the transformation, its value is converted to x3'. After applying equal width discretization on the transformed values, suppose x3' was assigned to bin #1. In this case, your answer for the equal-width method should be \"Yes it is affected by the transformation because ...\". However, if x3' remains in bin #2 after it was discretized, then your answer should be \"No it is not affected by the transformation because ...\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.** Consider the following 2-week bike rental dataset:\n",
    "\n",
    "<img src = \"figure2.jpg\" width=\"450\">\n",
    "\n",
    "The data set contains missing values for the weight attribute (denoted as **?** in the table). Compare the following three approaches for imputing the missing values:\n",
    "\n",
    "   **Approach 1:** Discard the missing values.\n",
    "\n",
    "   **Approach 2:** Replace the missing value with the global mean (i.e., average number of rentals for all the non-missing days).\n",
    "   \n",
    "   **Approach 3:** Replace the missing value with the stratified mean. For example, if the missing value is on a weekday, replace it by the average number of rentals for all non-missing weekdays.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)** What are the imputed values for day 1 and day 12 using approaches 2 and 3 described above?\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For approach 2, both day 1 and day 12 will be imputed by the average value of 170.\n",
    "\n",
    "For approach 3, day 1 will be imputed by the average weekday value of 140 whereas day 12 will be imputed by the average weekend value of 240."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Suppose we are interested in calculating the average number of rentals for all days (weekdays and weekends). Which approach, 2 or 3, will give the same average number of rentals for all days as approach 1?\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach 2. Replacing the missing value by the mean value will not change the overall mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Which of the three approaches is the best approach to deal with the missing value problem shown above. State your reasons clearly.\n",
    "\n",
    "**Solution**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach 1 is not reasonable due to the small sample size. Approach 2 is not reasonable due to the significant difference between the number of rentals during weekdays and weekends (i.e., weekends generally have much higher number of rentals compared to weekdays). Thus, imputing day 12 (which is a weekend) with the overall mean (170) will likely underestimate the number of rentals whereas imputing day 1 (which is a weekday) with the overall mean will likely overestimate the number of rentals. Approach 3 is therefore the best approach as it considers the type of day (weekday/weekend) when imputing the missing value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** Give a scenario in which approach 1 would be the best way to deal with the missing value problem.\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach 1 will be one of the best way to deal with the missing value problem if there is not significant difference between the number of weekend and weekday rentals and when the dataset spans a longer time period (i.e., for large sample size).   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.** In this exercise, you need to write a Python function that will implement the reservoir sampling approach described in class. Your Python function should take three input arguments: name of the input file, sample size (n), and seed (random_state) for the random number generator. The function should return the sample data as a data frame object. For this question, you can use the wiki_edit.txt file from lecture 4 as the input file. Set the sample size to be 10 and the random seed to be 1. \n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def reservoir_sampling(inputFile, n, random_state):\n",
    "    \"\"\"This function performs reservoir sampling from the given input file.\n",
    "    The function will return a dataframe object with n rows of records randomly\n",
    "    sampled with uniform probability from the input file.\"\"\"\n",
    "    \n",
    "    with open(inputFile,'r',encoding='utf-8') as f:\n",
    "        np.random.seed(random_state)\n",
    "        i = 0\n",
    "        buffer = []\n",
    "        for line in f:\n",
    "            if i < n:\n",
    "                fields = line.rstrip().split(sep=' ')\n",
    "                buffer.append(fields)\n",
    "            else:\n",
    "                r = np.random.rand()\n",
    "                if r <= n/i:\n",
    "                    j = np.random.randint(n)\n",
    "                    fields = line.rstrip().split(sep=' ')\n",
    "                    buffer[j] = fields\n",
    "            i = i+1\n",
    "        \n",
    "        sample = pd.DataFrame(buffer)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9061629</td>\n",
       "      <td>Palestine_(disambiguation)</td>\n",
       "      <td>2005-01-03</td>\n",
       "      <td>Mustafaa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9607632</td>\n",
       "      <td>List_of_important_publications_in_computer_sci...</td>\n",
       "      <td>2005-01-07</td>\n",
       "      <td>ip:145.97.222.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9354349</td>\n",
       "      <td>Kid_Icarus</td>\n",
       "      <td>2005-01-14</td>\n",
       "      <td>Drat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9363777</td>\n",
       "      <td>Ragtime_(novel)</td>\n",
       "      <td>2005-01-14</td>\n",
       "      <td>ip:24.44.209.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9227472</td>\n",
       "      <td>Fred_Seibert</td>\n",
       "      <td>2005-01-09</td>\n",
       "      <td>ip:67.117.218.13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0                                                  1           2  \\\n",
       "0  9061629                         Palestine_(disambiguation)  2005-01-03   \n",
       "1  9607632  List_of_important_publications_in_computer_sci...  2005-01-07   \n",
       "2  9354349                                         Kid_Icarus  2005-01-14   \n",
       "3  9363777                                    Ragtime_(novel)  2005-01-14   \n",
       "4  9227472                                       Fred_Seibert  2005-01-09   \n",
       "\n",
       "                  3  \n",
       "0          Mustafaa  \n",
       "1  ip:145.97.222.38  \n",
       "2              Drat  \n",
       "3  ip:24.44.209.217  \n",
       "4  ip:67.117.218.13  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = reservoir_sampling('wiki_edit.txt', 10, 1)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.** For this question, you need to apply various regression methods to predict the pollution level in Beijing, China. Download the dataset from https://archive.ics.uci.edu/ml/datasets/Beijing+PM2.5+Data. Click on the Data Folder tab and save the file on your local machine. \n",
    "\n",
    "**(a)** Load the file into a pandas DataFrame object named data. Drop the columns named 'No', 'year', and 'cbwd'. You should check for missing values (NaN) in the pm2.5 column using the notnull() function and remove the rows that have missing values.\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>pm2.5</th>\n",
       "      <th>DEWP</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>PRES</th>\n",
       "      <th>Iws</th>\n",
       "      <th>Is</th>\n",
       "      <th>Ir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>-16</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>1.79</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>148.0</td>\n",
       "      <td>-15</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>1020.0</td>\n",
       "      <td>2.68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>159.0</td>\n",
       "      <td>-11</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>181.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>5.36</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>138.0</td>\n",
       "      <td>-7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>1022.0</td>\n",
       "      <td>6.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  hour  pm2.5  DEWP  TEMP    PRES   Iws  Is  Ir\n",
       "24      1    2     0  129.0   -16  -4.0  1020.0  1.79   0   0\n",
       "25      1    2     1  148.0   -15  -4.0  1020.0  2.68   0   0\n",
       "26      1    2     2  159.0   -11  -5.0  1021.0  3.57   0   0\n",
       "27      1    2     3  181.0    -7  -5.0  1022.0  5.36   1   0\n",
       "28      1    2     4  138.0    -7  -5.0  1022.0  6.25   2   0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('beijing_pm25.csv', header='infer')\n",
    "data = data.drop(['No','year','cbwd'],axis=1)\n",
    "data = data[data['pm2.5'].notnull()] \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Standardize all the columns by subtracting each column with its corresponding mean and dividing by its standard deviation.\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24    0.330110\n",
       "25    0.536519\n",
       "26    0.656019\n",
       "27    0.895018\n",
       "28    0.427883\n",
       "Name: pm2.5, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = (data - data.mean())/data.std()\n",
    "X = Z.drop('pm2.5', axis=1)\n",
    "y = Z['pm2.5']\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Divide the data into training and test sets using a 70:30 split. \n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)** Apply multiple linear regression on the dataset and compute the RMSE (root mean square error) and R-square values of the model when applied to the test set. \n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error = 0.8485\n",
      "R-square = 0.2560\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create linear regression object\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Fit regression model to the training set\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Apply model to the test set\n",
    "y_pred_test = regr.predict(X_test)\n",
    "\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
    "print(\"R-square = %.4f\" % r2_score(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)** Apply Lasso regression with 5 fold cross validation to determine the best hyperparameter values. The regularizer alpha should be chosen from the set {0.005, 0.01, 0.02, 0.05, 0.1, 0.5, 0.8, 1.0}. Compute the RMSE (root mean square error) and R-square values of the model when applied to the test set. \n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected alpha = 0.01\n",
      "Root mean squared error = 0.8487\n",
      "R-square = 0.2556\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lasso = linear_model.LassoCV(cv=5, alphas=[0.005, 0.01, 0.02, 0.05, 0.1, 0.5, 0.8, 1.0, 5.0, 10.0])\n",
    "lasso.fit(X_train, y_train.ravel())\n",
    "y_pred_test_lasso = lasso.predict(X_test)\n",
    "\n",
    "print(\"Selected alpha = %.2f\" % lasso.alpha_)\n",
    "\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt(mean_squared_error(y_test, y_pred_test_lasso)))\n",
    "print(\"R-square = %.4f\" % r2_score(y_test, y_pred_test_lasso))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(f)** Apply multi-layer perceptron neural network with 1 hidden layer and 8 hidden nodes. Compute the RMSE (root mean square error) and R-square values of the model when applied to the test set. \n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error = 0.6779\n",
      "R-square = 0.5251\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neural_network\n",
    "\n",
    "mlp = neural_network.MLPRegressor(hidden_layer_sizes=(8,), activation='logistic', \n",
    "                                  max_iter=2000, random_state=1)\n",
    "mlp = mlp.fit(X_train, y_train.ravel())\n",
    "\n",
    "y_pred_test_mlp = mlp.predict(X_test)\n",
    "\n",
    "print(\"Root mean squared error = %.4f\" % np.sqrt(mean_squared_error(y_test, y_pred_test_mlp)))\n",
    "print(\"R-square = %.4f\" % r2_score(y_test, y_pred_test_mlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5.** Decision tree construction. \n",
    "\n",
    "**(a)** Draw a decision tree that would perfectly classify the dataset shown below. The dataset has 2 predictor attributes, denoted as x1 and x2, which were partitioned into 3 classes (denoted as A, B, and C). You can draw the tree using any software you want (e.g., powerpoint), save it as a jpeg/bmp/png image, and attach it to the notebook.\n",
    "\n",
    "<img src = \"dtree.jpg\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution:** Attach your decision tree figure here.\n",
    "\n",
    "<img src = \"dtree_2d.jpg\" width=\"450\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Consider the following training data for predicting whether there will be traffic congestion on a given segment of an interstate highway. Each data point corresponds to a particular time of day and is classified either as positive (if the highway segment was  congested) or negative (if it was not congested) class. Suppose you are interested in building a decision tree classifier on the training data. Compute the overall Gini index for each predictor attribute (construction and weather condition) and select the best attribute to partition the training data. \n",
    "\n",
    "<img src = \"congestion.jpg\" width=\"350\">\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gini index calculations for both predictor attributes are shown below:\n",
    "<img src = \"gini.jpg\" width=\"400\">\n",
    "Based on the information above, the attribute chosen to partition the data is Weather."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6.** Classifier Evaluation\n",
    "\n",
    "**(a)** Consider the decision tree shown below for classifying a dataset that contains examples that belong to 2 classes (positive or negative). The distribution of training examples that were assigned to each leaf node is also shown in the diagram. Draw a 2 $\\times$ 2 confusion matrix of the tree.\n",
    "\n",
    "<img src = \"dtree2.jpg\" width=\"300\">\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To answer this question, you must first convert the leaf nodes into class labels. This can be accomplished by assigning each node to the majority class of its training examples. The resulting tree is as shown below:\n",
    "<img src = \"dtree2b.jpg\" width=\"250\">\n",
    "\n",
    "To determine the confusion matrix, you need to count the number of positive and negative training examples predicted correctly/incorrectly by each leaf node of the tree. The resulting confusion matrix is shown below:\n",
    "<img src = \"confusion.jpg\" width=\"250\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Calculate the training error rate of the decision tree.\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error rate = (10 + 15)/ (35 + 15 + 10 + 40) = 25/100 = 0.25  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Calculate the F1-measure of the tree for the training data.\n",
    "\n",
    "**Solution:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the confusion matrix shown in part (a):\n",
    "\n",
    "Precision, p = 35/45 = 0.7778\n",
    "\n",
    "Recall, r = 35/50 = 0.70\n",
    "\n",
    "F1-measure = 2rp/(r + p) = 0.7369\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}